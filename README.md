# projectEngine – Backend

This repository contains the infrastructure for running asynchronous “build jobs” for projectEngine. Authenticated users can create a job, hold a real-time requirements conversation with the Client Relations agent over WebSockets, and follow the executive build once the agents start working. The final artifact is stored per user.

## Stack

- Django + Django REST Framework for the HTTP API
- Channels + Daphne for WebSockets
- Celery workers for background execution
- Redis (channel layer + Celery broker/result backend)
- PostgreSQL for persistence
- JWT authentication provided by the existing `authentication` app

## Domain Model

| Model    | Purpose                                                                                  |
|----------|------------------------------------------------------------------------------------------|
| `Job`    | Tracks the lifecycle of a build (owner, prompt, status, timestamps, optional error).    |
| `JobStep`| Ordered log of intermediate updates produced by the multi-agent system.                 |
| `App`    | The final structured artifact (JSON) generated by the job.                              |

Jobs emit updates to the WebSocket group `job_<job_id>` and persist the same information in the database so clients can reconcile on reconnect.

## API Overview

- `POST /api/jobs/` – create a job for the authenticated user, returns the job id and initial state.
- `GET /api/jobs/<job_id>/` – fetch job details + ordered steps (owner-only).
- `GET /api/jobs/` – list the caller’s jobs (paginated).
- `GET /api/apps/` – list app artifacts owned by the caller.
- `GET /api/apps/<id>/` – retrieve an app by ID.
- `GET /api/apps/by-job/<job_id>/` – fetch the app that belongs to a specific job.
- `GET /api/job-messages/?job_id=<job_id>` – fetch chat + description history for a specific job (oldest → newest).
- WebSocket: `ws://<host>/ws/jobs/<job_id>/` (include `Authorization: Bearer <JWT>`; in dev you may also append `?token=<JWT>` when `ALLOW_WS_TOKEN_QUERY` is enabled for quick testing).

All endpoints require authentication (JWT) except those under `/api/auth/`.

## Runtime Flow

1. `POST /api/jobs/` stores a `Job` with status `collecting`. The initial idea is persisted as both the original prompt and the first chat message.
2. The backend immediately invokes the agentLoop `RequirementsGatherer`, records the agent’s reply, and streams it via `/ws/jobs/<job_id>/`.
3. The user and the Client Relations agent continue exchanging `{"kind":"chat","content":"..."}` messages over the socket. Every turn is saved in `JobMessage` and broadcast to connected clients.
4. Once the agent emits `REQUIREMENTS_SUMMARY`, the backend finalizes the requirements, updates the job status to `queued`, and enqueues `jobs.tasks.run_job_task`.
5. The Celery worker sets the job status to `running` and hands the refined requirements to the agentLoop executive discussion (CEO/CTO/Secretary). Each agent turn is recorded as a `JobStep` and streamed.
6. When the discussion finishes, the generated spec (requirements, history, PRD summary) is attached to `App.spec` and broadcast with an `app` event.

You can still swap the orchestrator by pointing `AGENT_ORCHESTRATOR_PATH` to another callable, but the default now integrates directly with `agentLoop`.

> agentLoop sources live under `server/agentLoop`. If you relocate them, set `AGENT_LOOP_PATH` so the backend can import the package.

## Running Locally (Docker)

```bash
cd server
docker-compose up --build
```

Services:
- `web`: Django + Daphne ASGI server (HTTP + WebSockets)
- `worker`: Celery worker processing background jobs
- `db`: PostgreSQL 16
- `redis`: Broker/channel layer

The compose file automatically runs migrations on start. Copy `.envtemplate` to `.env`, adjust `AGENT_LOOP_PATH`, `OPENAI_API_KEY`, and other secrets before running outside local development.

## Running Without Docker

1. Install dependencies:
   ```bash
   cd server
   python -m venv .venv && .venv\Scripts\activate  # Windows example
   pip install -r requirements.txt
   ```
2. Start Redis and Postgres locally.
3. Export the environment variables from `.envtemplate`.
4. Launch services:
   ```bash
   python manage.py migrate
   daphne -b 0.0.0.0 -p 8000 server.asgi:application  # HTTP + WS
   celery -A server worker -l info                    # background jobs
   ```

## Testing the WebSocket

1. Create a job via `POST /api/jobs/`.
2. Connect to `ws://localhost:8000/ws/jobs/<job_id>/` with the same JWT you used for HTTP (Channels shares Django auth; plug in your JWT-to-scope middleware as needed).
3. Send chat payloads such as:
   ```json
   {"kind": "chat", "content": "Here are more details about the target users."}
   ```
4. Observe `chat`, `description`, `status`, `step`, and `app` payloads as the job progresses from requirements gathering through build-out.

## Next Steps

- Plug in the real multi-agent orchestration module using `AGENT_ORCHESTRATOR_PATH`.
- Harden authentication for Channels scope (e.g., JWT auth middleware).
- Add observability (metrics/log forwarding) for long-running jobs.